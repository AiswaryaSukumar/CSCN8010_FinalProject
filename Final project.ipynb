{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e20579b",
   "metadata": {},
   "source": [
    "# AI-Enhanced Self-Service Portal for Student Affairs: A Proof of Concept\n",
    "\n",
    "**Course:** CSCN 8010 – Foundations of Machine Learning  \n",
    "**Project:** AI-Enhanced Self-Service Portal for Student Affairs  \n",
    "**Team:** \n",
    "| Aiswarya Thekkuveettil Thazhath               | 8993970    |   \n",
    "| Vishnu Sivaraj                                | 9025320    |         \n",
    "| Rohit Iyer                                    | 8993045    |                            \n",
    "| Cemil Caglar Yapici                           | 9081058    |\n",
    " \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d4175",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Student Success Advisors (SSAs) at Conestoga College currently experience a high volume of repetitive, low-complexity inquiries from students.\n",
    "Due to recent staffing reductions, SSAs face increasing workload pressure, leading to slower response times and inefficiencies.\n",
    "\n",
    "This project presents a Proof of Concept (PoC) for an AI-enhanced self-service chatbot capable of:\n",
    "\n",
    "Answering FAQs across multiple Student Affairs domains\n",
    "\n",
    "Routing complex or serious queries to human advisors (\"off-ramp\")\n",
    "\n",
    "Supporting multilingual responses\n",
    "\n",
    "Reducing SSA workload by automating high-volume inquiries\n",
    "\n",
    "This notebook details the full methodology, data pipeline, model development, evaluation, and final system design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef879946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Environment Setup & Imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to Python path so that `src.*` imports work\n",
    "PROJECT_ROOT = Path.cwd()  # adjust if running notebook from a different directory\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "src_path = PROJECT_ROOT / \"src\"\n",
    "if src_path.exists():\n",
    "    sys.path.append(str(PROJECT_ROOT))  # so `from src.x import y` works\n",
    "else:\n",
    "    print(\"⚠️ WARNING: src/ folder not found. Adjust PROJECT_ROOT as needed.\")\n",
    "\n",
    "# Core project modules\n",
    "from src import retrieval_service\n",
    "from src import intent_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b22481",
   "metadata": {},
   "source": [
    "## 2. Problem Statement & Objectives\n",
    "\n",
    "2.1 Problem Statement\n",
    "\n",
    "Students frequently ask questions related to:\n",
    "\n",
    "Fees and due dates\n",
    "\n",
    "Orientation\n",
    "\n",
    "Student rights and responsibilities\n",
    "\n",
    "Registrar processes\n",
    "\n",
    "Career services\n",
    "\n",
    "Many of these questions are repetitive and answerable via existing web pages, but students often bypass the documentation and message SSAs directly.\n",
    "\n",
    "2.2 Objectives\n",
    "\n",
    "Build a centralized Knowledge Base (KB) from authenticated college sources.\n",
    "\n",
    "Develop an information retrieval system that returns accurate answers from the KB.\n",
    "\n",
    "Train a machine learning intent classifier to categorize queries.\n",
    "\n",
    "Implement a crisis detection mechanism for high-risk messages (e.g., mental health concerns).\n",
    "\n",
    "Build a Streamlit-based chatbot UI for live interaction.\n",
    "\n",
    "Provide an academic evaluation and discuss limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add55caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Raw Data Overview\n",
    "\n",
    "data_dir = PROJECT_ROOT / \"data\"\n",
    "\n",
    "raw_files = [\n",
    "    \"career_centre_faq.csv\",\n",
    "    \"orientation_faq.csv\",\n",
    "    \"student_fees_faq_winter_2024.csv\",\n",
    "    \"student_rights_faq.csv\",\n",
    "    \"winter_2024_registrar_faq.csv\",\n",
    "    \"success_portal_resources.csv\",\n",
    "]\n",
    "\n",
    "for fname in raw_files:\n",
    "    fpath = data_dir / fname\n",
    "    if fpath.exists():\n",
    "        df = pd.read_csv(fpath)\n",
    "        print(f\"\\n=== {fname} ===\")\n",
    "        print(df.head(3))\n",
    "        print(\"Rows:\", len(df))\n",
    "    else:\n",
    "        print(f\"⚠️ {fname} not found in {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7cea8",
   "metadata": {},
   "source": [
    "## 3. Data Sources\n",
    "\n",
    "The following authenticated data sources were scraped:\n",
    "\n",
    "Source\tDescription\n",
    "Orientation FAQ\tNew student orientation questions\n",
    "Student Rights FAQ\tPolicies, complaints, appeals\n",
    "Student Fees FAQ (Winter 2024)\tTuition deadlines, refunds, OSAP\n",
    "Registrar FAQ\tAcademic records, transcripts, scheduling\n",
    "Career Centre FAQ\tEmployment and career services\n",
    "Success Portal\tAcademic support and resources\n",
    "\n",
    "Each dataset is stored as a CSV with fields:\n",
    "\n",
    "question\n",
    "\n",
    "answer\n",
    "\n",
    "source_url\n",
    "\n",
    "source_type (added during cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c49d7",
   "metadata": {},
   "source": [
    "## 4. Data Collection (Web Scraping)\n",
    "\n",
    "Python scripts using requests + BeautifulSoup collected structured Q&A data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14287a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "entries = soup.find_all(\"details\")\n",
    "\n",
    "for entry in entries:\n",
    "    question = entry.find(\"summary\").get_text(strip=True)\n",
    "    answer = \" \".join(p.get_text(strip=True) for p in entry.find_all(\"p\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa01146",
   "metadata": {},
   "source": [
    "Ethical considerations\n",
    "\n",
    "Only publicly available educational FAQ pages were scraped.\n",
    "\n",
    "No authentication-protected data was accessed.\n",
    "\n",
    "No personal identifiers were collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a33c5a",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning & Knowledge Base Construction\n",
    "\n",
    "All scraped CSVs were combined using cleanProcess.ipynb into a unified knowledge base:\n",
    "\n",
    "5.1 Cleaning Steps\n",
    "\n",
    "Remove duplicate questions\n",
    "\n",
    "Normalize whitespace\n",
    "\n",
    "Standardize formatting\n",
    "\n",
    "Add source_type labels\n",
    "\n",
    "Verify each row has a valid question & answer\n",
    "\n",
    "5.2 Final Knowledge Base\n",
    "\n",
    "student_affairs_knowledge_base.csv\n",
    "\n",
    "question\tanswer\tsource_url\tsource_type\n",
    "\n",
    "This knowledge base serves as the foundation for the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c63c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load Unified Knowledge Base\n",
    "\n",
    "kb_path = data_dir / \"student_affairs_knowledge_base.csv\"\n",
    "kb = pd.read_csv(kb_path)\n",
    "\n",
    "print(\"Knowledge Base shape:\", kb.shape)\n",
    "kb.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244058e",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Retrieval Index\n",
    "\n",
    "To support fast lookup, we built a **TF-IDF (Term Frequency–Inverse Document Frequency)** index over the questions in the knowledge base.\n",
    "\n",
    "**Why TF-IDF?**\n",
    "\n",
    "- Simple and efficient  \n",
    "- Works well for FAQ-style queries  \n",
    "- Provides interpretable similarity scores  \n",
    "- Serves as a strong baseline for information retrieval  \n",
    "\n",
    "We use:\n",
    "\n",
    "- `TfidfVectorizer` from scikit-learn  \n",
    "- Unigrams + bigrams (`ngram_range=(1, 2)`)  \n",
    "- English stopword removal  \n",
    "- Cosine similarity for matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fe7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Building the TF-IDF Index (Offline Step)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "def build_tfidf_index(kb_df, save_dir=PROJECT_ROOT / \"models\"):\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    questions = kb_df[\"question\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=\"english\",\n",
    "        max_df=0.8,\n",
    "        min_df=1,\n",
    "    )\n",
    "    X = vectorizer.fit_transform(questions)\n",
    "\n",
    "    vec_path = save_dir / \"tfidf_vectorizer_v2.pkl\"\n",
    "    mat_path = save_dir / \"kb_tfidf_matrix_v2.npz\"\n",
    "\n",
    "    joblib.dump(vectorizer, vec_path)\n",
    "    sparse.save_npz(mat_path, X)\n",
    "\n",
    "    print(\"Saved vectorizer →\", vec_path)\n",
    "    print(\"Saved matrix     →\", mat_path)\n",
    "    print(\"Shape:\", X.shape)\n",
    "\n",
    "# Uncomment to rebuild if needed:\n",
    "# build_tfidf_index(kb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c409a",
   "metadata": {},
   "source": [
    "## 6. Semantic Embeddings (HuggingFace)\n",
    "\n",
    "To capture deeper semantic similarity, we used a pre-trained sentence embedding model:\n",
    "\n",
    "- **Model:** `sentence-transformers/all-MiniLM-L6-v2`\n",
    "\n",
    "This model encodes a sentence into a dense vector.  \n",
    "We can then compute cosine similarity between queries and FAQ questions, which helps when wording differs significantly.\n",
    "\n",
    "We combined:\n",
    "\n",
    "- TF-IDF similarity  \n",
    "- Embedding similarity  \n",
    "\n",
    "to improve matching robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Sentence Embedding Example\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "\n",
    "# Embed a small sample\n",
    "sample_questions = kb[\"question\"].head(5).tolist()\n",
    "embeddings = encode_texts(sample_questions)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa70c1",
   "metadata": {},
   "source": [
    "## 7. Intent Classification Model\n",
    "\n",
    "Not every user message should be treated as a simple FAQ lookup.  \n",
    "We trained an intent classifier to distinguish between:\n",
    "\n",
    "- `small_talk` – greetings or casual conversation  \n",
    "- `student_affairs` – in-scope questions (fees, services, policies, etc.)  \n",
    "- `out_of_scope` – unrelated topics (e.g., weather, math problems)  \n",
    "- `serious_issue` – potential crisis, self-harm, or mental health risks  \n",
    "\n",
    "### 7.1 Training Data\n",
    "\n",
    "We used `training_data.csv`, which contains text examples and labels.  \n",
    "The model was trained using a neural network (defined in `trainingmodel_intent.ipynb`) and exported as:\n",
    "\n",
    "- `intent_classifier_best.pt` – PyTorch model weights  \n",
    "- `intent_label_encoder.pkl` – maps integer indices back to label strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Testing the Intent Classifier\n",
    "\n",
    "from src.intent_classifier import classify_intent\n",
    "\n",
    "test_queries = [\n",
    "    \"hi\",\n",
    "    \"how do I pay my fees?\",\n",
    "    \"I want to book an appointment with a success advisor\",\n",
    "    \"I feel like hurting myself\",\n",
    "    \"what's the weather today?\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    intent = classify_intent(q)\n",
    "    print(f\"Query: {q!r}\")\n",
    "    print(\" → Intent:\", intent.get(\"label\"), \"| Score:\", intent.get(\"score\"))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcb16d",
   "metadata": {},
   "source": [
    "## 8. Retrieval & Answer Generation\n",
    "\n",
    "The **retrieval_service** module implements the core logic for:\n",
    "\n",
    "1. Loading the TF-IDF index and knowledge base  \n",
    "2. Classifying intent  \n",
    "3. Detecting crisis-related language (using emotion detection and keyword rules)  \n",
    "4. Retrieving relevant FAQ entries  \n",
    "5. Optionally calling an LLM for answer synthesis (OpenAI; disabled in our environment due to quota)\n",
    "\n",
    "At inference, the pipeline is:\n",
    "\n",
    "1. **Intent** ← `classify_intent(query)`  \n",
    "2. If `serious_issue` → return crisis response  \n",
    "3. Else if `small_talk` → return greeting  \n",
    "4. Else if `out_of_scope` → return “out of scope”  \n",
    "5. Else → run TF-IDF + embeddings → retrieve best FAQ → return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. End-to-End Answer Pipeline\n",
    "\n",
    "from src.retrieval_service import load_resources, answer_query\n",
    "\n",
    "# Ensure resources are loaded (TF-IDF + KB)\n",
    "load_resources()\n",
    "\n",
    "demo_queries = [\n",
    "    \"How do I pay my fees?\",\n",
    "    \"Where can I find information about student rights?\",\n",
    "    \"How do I contact the career centre?\",\n",
    "    \"I feel depressed and don't know what to do.\"\n",
    "]\n",
    "\n",
    "for q in demo_queries:\n",
    "    print(\"=\"*80)\n",
    "    print(\"User:\", q)\n",
    "    result = answer_query(q)\n",
    "    print(\"Mode:\", result.get(\"mode\", \"N/A\"))\n",
    "    print(\"Answer:\\n\", result.get(\"answer\"))\n",
    "    if \"matched_question\" in result:\n",
    "        print(\"\\nMatched KB question:\", result[\"matched_question\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b898b3f",
   "metadata": {},
   "source": [
    "## 9. User Interface (Streamlit Chatbot)\n",
    "\n",
    "The final user-facing interface is implemented with **Streamlit** in `app.py`.\n",
    "\n",
    "Key features:\n",
    "\n",
    "- Chat-style interface with separate user and bot bubbles  \n",
    "- Language selectors (English, French, Hindi) using `deep-translator`  \n",
    "- A right-hand sidebar for announcements and student news  \n",
    "- A “typing…” placeholder while responses are computed  \n",
    "\n",
    "To run the app:\n",
    "\n",
    "```bash\n",
    "streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93990e1c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Architecture Diagram & Discussion\n",
    "\n",
    "```markdown\n",
    "## 10. System Architecture\n",
    "\n",
    "The overall system architecture is:\n",
    "\n",
    "1. **Data Layer**\n",
    "   - Scraped FAQ CSVs\n",
    "   - Unified KB: `student_affairs_knowledge_base.csv`\n",
    "\n",
    "2. **Model Layer**\n",
    "   - TF-IDF vectorizer + matrix\n",
    "   - Sentence embedding model (HuggingFace)\n",
    "   - Intent classifier (PyTorch)\n",
    "   - Optional LLM (OpenAI) for synthesized answers\n",
    "\n",
    "3. **Application Layer**\n",
    "   - `retrieval_service.py`\n",
    "   - `intent_classifier.py`\n",
    "   - `llm_service.py`\n",
    "   - `translation.py`\n",
    "\n",
    "4. **Presentation Layer**\n",
    "   - Streamlit app (`app.py`)\n",
    "\n",
    "This layered design supports modularity and future extension (e.g., replacing the LLM, changing embeddings, or adding new FAQ sources).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408ae80",
   "metadata": {},
   "source": [
    "## 11. Evaluation\n",
    "\n",
    "### 11.1 Retrieval Quality\n",
    "\n",
    "We manually evaluated system responses across multiple domains:\n",
    "\n",
    "- Student fees\n",
    "- Orientation\n",
    "- Student rights\n",
    "- Career centre\n",
    "- Registrar\n",
    "\n",
    "(Here you can add a table of examples with: query, expected answer, retrieved answer.)\n",
    "\n",
    "### 11.2 Intent Classification\n",
    "\n",
    "From the validation set of `training_data.csv`, we measured:\n",
    "\n",
    "- Accuracy: *[fill in]*\n",
    "- Precision / Recall / F1 for each class: *[fill in]*\n",
    "\n",
    "### 11.3 Limitations\n",
    "\n",
    "- The OpenAI API is limited by quota, so generative answers may fall back to defaults.\n",
    "- Some complex questions still require human interpretation.\n",
    "- The current system does not integrate with secure student records or personalized data.\n",
    "- Multilingual support relies on machine translation and has not been fully evaluated for accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6745e33",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
